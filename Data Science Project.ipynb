{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944ebbaf",
   "metadata": {},
   "source": [
    "# PROBLEM DEFINITION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e95df074",
   "metadata": {},
   "source": [
    "Lung cancer remains a significant global health challenge, with its early detection and type classification being crucial for\n",
    "effective treatment. One detection method involves analyzing CT scan images. These images can then be interpreted by doctors to\n",
    "determine the presence and type of lung cancer. However, this method has limitations; human interpretation may miss subtle\n",
    "patterns indicative of early-stage lung cancer. In contrast, deep learning models offer a promising avenue on this matter. They\n",
    "excel in recognizing intricate patterns, identifying subtle abnormalities not easily observable through other methods. Another \n",
    "advantage is they automatically learn relevant features from data, eliminating the need for manual feature engineeing, which is\n",
    "particulary usefull in medical imaging where definining explicit features can be complex.\n",
    "Here, we use a dataset containing CT scan images of lungs categorized as normal, squamous cell carcinoma,\n",
    "adenocarcinoma and large cell carcinoma. Our objective is to train three different models (VGG16, Inceptionv3 and EfficientNetB0), and compare their accuracy and make predictions with the one with hightest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.models import Sequential, load_model, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e07104a",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION AND VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a5b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Directory for both the train and test\n",
    "train_path = \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/train\"\n",
    "val_path = \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/valid\"\n",
    "test_path = \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to count number of images per class using a dictionary\n",
    "def GetDatasetSize(path):\n",
    "    num_of_image = {}\n",
    "    for folder in os.listdir(path):\n",
    "        # count files in the folder\n",
    "        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n",
    "    return num_of_image;\n",
    "\n",
    "# Get the number of images per class in each set (train, validation and test)\n",
    "train_set = GetDatasetSize(train_path)\n",
    "val_set = GetDatasetSize(val_path)\n",
    "test_set = GetDatasetSize(test_path)\n",
    "print(train_set,\"\\n\\n\",val_set,\"\\n\\n\",test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45f75d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labels for each classs\n",
    "labels = ['squamous.cell.carcinoma', 'normal', 'adenocarcinoma', 'large.cell.carcinoma']\n",
    "\n",
    "# Create lists from previous dictionaries storing the count of images per category\n",
    "train_list = list(train_set.values())\n",
    "val_list = list(val_set.values())\n",
    "test_list = list(test_set.values())\n",
    "\n",
    "# Labels location and bars widht \n",
    "x = np.arange(len(labels))  \n",
    "width = 0.25  \n",
    "\n",
    "# Create plot and 3 sets of bars (train, val, test)\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, train_list, width, label='Train')\n",
    "rects2 = ax.bar(x, val_list, width, label='Val')\n",
    "rects3 = ax.bar(x + width, test_list, width, label='Test')\n",
    "\n",
    "# Add labels, title, legend, count values...\n",
    "ax.set_ylabel('Images Count')\n",
    "ax.set_title('Dataset')\n",
    "ax.set_xticks(x, labels)\n",
    "plt.xticks(rotation=15)\n",
    "ax.legend()\n",
    "ax.bar_label(rects1)\n",
    "ax.bar_label(rects2)\n",
    "ax.bar_label(rects3)\n",
    "\n",
    "# Optimized layout and displaying plot\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb783cc5",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data generator with specified augmentation configurations (mostly geometric transformations)\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
    "                                  horizontal_flip = True,\n",
    "                                  fill_mode = 'nearest',\n",
    "                                  zoom_range=0.2,\n",
    "                                  shear_range = 0.2,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  rotation_range=0.4)\n",
    "\n",
    "# Using data generator to create augmented data from image files in train_path directory\n",
    "train_data = train_datagen.flow_from_directory(train_path,\n",
    "                                                   batch_size = 5,\n",
    "                                                   target_size = (350,350),\n",
    "                                                   class_mode = 'categorical')\n",
    "\n",
    "# Dicctionary with class names to their respective indices in the generated data\n",
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "val_data = val_datagen.flow_from_directory(val_path,\n",
    "                                                   batch_size = 5,\n",
    "                                                   target_size = (350,350),\n",
    "                                                   class_mode = 'categorical')\n",
    "val_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bc9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
    "test_data = test_datagen.flow_from_directory(test_path,\n",
    "                                                   batch_size = 5,\n",
    "                                                   target_size = (350,350),\n",
    "                                                   class_mode = 'categorical')\n",
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dcbd17",
   "metadata": {},
   "source": [
    "# SAMPLE VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot sample images with labels\n",
    "def plot_sample_images(images, labels, class_indices):\n",
    "    class_labels = list(class_indices.keys())\n",
    "    fig, axs = plt.subplots(1, len(images), figsize=(15, 5))  \n",
    "    fig.subplots_adjust(wspace=0.5)  # Adjust the width space between subplots\n",
    "\n",
    "    for i in range(len(images)):\n",
    "        axs[i].imshow(images[i])\n",
    "        axs[i].set_title(\"Label: {}\".format(class_labels[np.argmax(labels[i])]), fontsize=10)  \n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Sample and plotting of 3 images with their respective labels from train_data\n",
    "sample_images, sample_labels = next(train_data)\n",
    "plot_sample_images(sample_images[:3], sample_labels[:3], train_data.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b05e3b",
   "metadata": {},
   "source": [
    "# VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca22deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    input_shape=(350,350,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the number of classes in the classification problem.\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# First, a sequential model is created, which will be used to build the VGG model.\n",
    "vgg_model = Sequential()\n",
    "\n",
    "# Se agrega una capa al modelo. base_model el modelo anteriormente preentrenado.\n",
    "vgg_model.add(base_model)\n",
    "\n",
    "# A flattening layer (Flatten) is added. This layer converts the output from the \n",
    "# previous layer (which is likely a three-dimensional tensor) into a one-dimensional vector.\n",
    "vgg_model.add(layers.Flatten())\n",
    "\n",
    "# A Dropout layer is added with a dropout rate of 25%. Dropout is used to prevent overfitting \n",
    "# by randomly disconnecting some neurons during training.\n",
    "vgg_model.add(layers.Dropout(0.25))\n",
    "\n",
    "# A dense layer is added with NUM_CLASSES neurons and a sigmoid activation function. \n",
    "# This layer produces the final output of the model.\n",
    "vgg_model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "# The first layer of the model (base_model) is frozen, so the weights of this layer \n",
    "# will not be updated during training.\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "# The model is compiled with the 'categorical_crossentropy' loss function,\n",
    "#' adam' optimizer, and the accuracy metric. This prepares the model for training.\n",
    "vgg_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff6225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(\n",
    "    filepath=\"./ct_vgg_best_model.hdf5\",\n",
    "    monitor= 'val_accuracy', \n",
    "    verbose= 1,\n",
    "    save_best_only= True, \n",
    "    mode = 'auto'\n",
    "    );\n",
    "\n",
    "call_back = [ mc];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c1ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Model\n",
    "vgg = vgg_model.fit(\n",
    "    train_data, \n",
    "    steps_per_epoch = train_data.samples//train_data.batch_size, \n",
    "    epochs = 32, \n",
    "    validation_data = val_data, \n",
    "    validation_steps = val_data.samples//val_data.batch_size,\n",
    "    callbacks = call_back \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc84b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Best Fit Model \n",
    "model = load_model(\"./ct_vgg_best_model.hdf5\")\n",
    "\n",
    "# Checking the Accuracy of the Model \n",
    "accuracy_vgg = model.evaluate_generator(generator= test_data)[1] \n",
    "print(f\"The accuracy of the model is = {accuracy_vgg*100} %\")\n",
    "loss_vgg = model.evaluate_generator(generator= test_data)[0] \n",
    "print(f\"The loss of the model is = {loss_vgg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02324ab3",
   "metadata": {},
   "source": [
    "# INCEPTIONV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(input_shape = (350, 350, 3), \n",
    "                         include_top = False, \n",
    "                         weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code then iterates through all layers in the base InceptionV3 model. \n",
    "# This means that during training, these layers will not be updated, preserving the pre-trained knowledge.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we flatten the information coming out of InceptionV3 (making it simpler).\n",
    "# We aded another layer for better understanding of the flattened information\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "\n",
    "# Finally, we add a layer with 4 'neurons' that will help us classify things into different categories.\n",
    "x = layers.Dense(4, activation='sigmoid')(x)\n",
    "\n",
    "# We put together the original InceptionV3 and our new custom parts \n",
    "model_incep = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "# Compile up the rules and tools for training your neural network. \n",
    "# The optimizer determines how the model should update its internal parameters, the loss function quantifies how well the model is doing, and the metrics provide additional measures to track the model's performance.\n",
    "model_incep.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), \n",
    "                    loss = 'categorical_crossentropy', \n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66606298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Model check point Callback\n",
    "\n",
    "mc = ModelCheckpoint(\n",
    "    filepath=\"./ct_incep_best_model.hdf5\",\n",
    "    monitor= 'val_accuracy', \n",
    "    verbose= 1,\n",
    "    save_best_only= True, \n",
    "    mode = 'auto'\n",
    "    );\n",
    "\n",
    "call_back = [mc];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Model\n",
    "incep = model_incep.fit(\n",
    "    train_data, \n",
    "    steps_per_epoch = train_data.samples//train_data.batch_size, \n",
    "    epochs = 32, \n",
    "    validation_data = val_data, \n",
    "    validation_steps = val_data.samples//val_data.batch_size,\n",
    "    callbacks = call_back \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98d6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Best Fit Model \n",
    "model = load_model(\"./ct_incep_best_model.hdf5\")\n",
    "\n",
    "# Checking the Accuracy of the Model \n",
    "accuracy_incep = model.evaluate_generator(generator= test_data)[1] \n",
    "print(f\"The accuracy of the model is = {accuracy_incep*100} %\")\n",
    "loss_incep = model.evaluate_generator(generator= test_data)[0]\n",
    "print(f\"The loss the model is = {loss_incep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970b00e",
   "metadata": {},
   "source": [
    "# EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c722ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB0(input_shape = (350, 350, 3), \n",
    "                         include_top = False, \n",
    "                         weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint(\n",
    "    filepath=\"./ct_effnet_best_model.hdf5\",\n",
    "    monitor= 'val_accuracy', \n",
    "    verbose= 1,\n",
    "    save_best_only= True, \n",
    "    mode = 'auto'\n",
    "    );\n",
    "\n",
    "call_back = [ mc];\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)\n",
    "\n",
    "#We also add a earlystop for prevent the computer from wasting time if it's not making progress.\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8579d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customize our base model\n",
    "EffNetmodel = base_model.output\n",
    "EffNetmodel = tf.keras.layers.GlobalAveragePooling2D()(EffNetmodel)\n",
    "# to provide overfitting problem\n",
    "EffNetmodel = tf.keras.layers.Dropout(rate=0.5)(EffNetmodel)\n",
    "\n",
    "#Finally, we add a layer with 4 'neurons' that will help us classify things into different categories.\n",
    "EffNetmodel = tf.keras.layers.Dense(4,activation='softmax')(EffNetmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814906d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We put together the original EfficientNetB0 and our new custom parts \n",
    "EffNetmodel = tf.keras.models.Model(inputs=base_model.input, outputs = EffNetmodel)\n",
    "\n",
    "#The optimizer determines how the model should update its internal parameters, the loss function quantifies how well the model is doing, and the metrics provide additional measures to track the model's performance.\n",
    "EffNetmodel.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1597b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "EffNetB0 = EffNetmodel.fit(\n",
    "    train_data, \n",
    "    steps_per_epoch = train_data.samples//train_data.batch_size, \n",
    "    epochs = 32, \n",
    "    validation_data = val_data, \n",
    "    validation_steps = val_data.samples//val_data.batch_size,\n",
    "    callbacks = [tensorboard, mc, reduce_lr, early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f153a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Best Fit Model \n",
    "model_eff = load_model(\"./ct_effnet_best_model.hdf5\")\n",
    "\n",
    "# Checking the Accuracy of the Model \n",
    "accuracy_effnet = model_eff.evaluate_generator(generator= test_data)[1] \n",
    "loss_effnet = model_eff.evaluate_generator(generator= test_data)[0]\n",
    "print(f\"The accuracy of the model is = {accuracy_effnet*100} %\")\n",
    "print(f\"The loss of the model is = {loss_effnet} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d47c6",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe05793",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['VGG16', 'InceptionV3', 'EfficientNetB0']\n",
    "accuracy = [accuracy_vgg, accuracy_incep, accuracy_effnet]\n",
    "accuracy = np.floor([i * 100 for i in accuracy])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(algos, accuracy, color='skyblue')\n",
    "\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffeb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['VGG16', 'InceptionV3', 'EfficientNetB0']\n",
    "loss = [loss_vgg, loss_incep, loss_effnet]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(algos, loss, color='skyblue')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 3), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Comparison')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9da2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9629d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a function to import an image and resize it to be able to be used with our model\n",
    "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
    "  \"\"\"\n",
    "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
    "  (224, 224, 3).\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename (str): string filename of target image\n",
    "  img_shape (int): size to resize target image to, default 224\n",
    "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
    "  \"\"\"\n",
    "  # Read in the image\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Decode it into a tensor\n",
    "  img = tf.image.decode_jpeg(img)\n",
    "  # Resize the image\n",
    "  img = tf.image.resize(img, [img_shape, img_shape])\n",
    "  if scale:\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    return img/255.\n",
    "  else:\n",
    "    return img\n",
    "\n",
    "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
    "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
    "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
    "\n",
    "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
    "  will be used.\n",
    "\n",
    "  Args:\n",
    "    y_true: Array of truth labels (must be same shape as y_pred).\n",
    "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
    "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
    "    figsize: Size of output figure (default=(10, 10)).\n",
    "    text_size: Size of output figure text (default=15).\n",
    "    norm: normalize values or not (default=False).\n",
    "    savefig: save confusion matrix to file (default=False).\n",
    "  \n",
    "  Returns:\n",
    "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
    "\n",
    "  Example usage:\n",
    "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
    "                          y_pred=y_preds, # predicted labels\n",
    "                          classes=class_names, # array of class label names\n",
    "                          figsize=(15, 15),\n",
    "                          text_size=10)\n",
    "  \"\"\"  \n",
    "  # Create the confustion matrix\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
    "\n",
    "  # Plot the figure and make it pretty\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
    "  fig.colorbar(cax)\n",
    "\n",
    "  # Are there a list of classes?\n",
    "  if classes:\n",
    "    labels = classes\n",
    "  else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "  \n",
    "  # Label the axes\n",
    "  ax.set(title=\"Confusion Matrix\",\n",
    "         xlabel=\"Predicted label\",\n",
    "         ylabel=\"True label\",\n",
    "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
    "         yticks=np.arange(n_classes), \n",
    "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
    "         yticklabels=labels)\n",
    "  \n",
    "  # Make x-axis labels appear on bottom\n",
    "  ax.xaxis.set_label_position(\"bottom\")\n",
    "  ax.xaxis.tick_bottom()\n",
    "\n",
    "  # Set the threshold for different colors\n",
    "  threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "  # Plot the text on each cell\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    if norm:\n",
    "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "    else:\n",
    "      plt.text(j, i, f\"{cm[i, j]}\",\n",
    "              horizontalalignment=\"center\",\n",
    "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "              size=text_size)\n",
    "\n",
    "  # Save the figure to the current working directory\n",
    "  if savefig:\n",
    "    fig.savefig(\"confusion_matrix.png\")\n",
    "  \n",
    "# Make a function to predict on images and plot them (works with multi-class)\n",
    "def pred_and_plot(model, filename, class_names):\n",
    "  \"\"\"\n",
    "  Imports an image located at filename, makes a prediction on it with\n",
    "  a trained model and plots the image with the predicted class as the title.\n",
    "  \"\"\"\n",
    "  # Import the target image and preprocess it\n",
    "  img = load_and_prep_image(filename)\n",
    "\n",
    "  # Make a prediction\n",
    "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "  # Get the predicted class\n",
    "  if len(pred[0]) > 1: # check for multi-class\n",
    "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
    "  else:\n",
    "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
    "\n",
    "  # Plot the image and predicted class\n",
    "  plt.imshow(img)\n",
    "  plt.title(f\"Prediction: {pred_class}\")\n",
    "  plt.axis(False);\n",
    "  \n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  \"\"\"\n",
    "  Creates a TensorBoard callback instand to store log files.\n",
    "\n",
    "  Stores log files with the filepath:\n",
    "    \"dir_name/experiment_name/current_datetime/\"\n",
    "\n",
    "  Args:\n",
    "    dir_name: target directory to store TensorBoard log files\n",
    "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
    "  \"\"\"\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "  )\n",
    "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "  return tensorboard_callback\n",
    "\n",
    "# Plot the validation and training data separately\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "\n",
    "  Args:\n",
    "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();\n",
    "\n",
    "def compare_historys(original_history, new_history, initial_epochs=5):\n",
    "    \"\"\"\n",
    "    Compares two TensorFlow model History objects.\n",
    "    \n",
    "    Args:\n",
    "      original_history: History object from original model (before new_history)\n",
    "      new_history: History object from continued model training (after original_history)\n",
    "      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get original history measurements\n",
    "    acc = original_history.history[\"accuracy\"]\n",
    "    loss = original_history.history[\"loss\"]\n",
    "\n",
    "    val_acc = original_history.history[\"val_accuracy\"]\n",
    "    val_loss = original_history.history[\"val_loss\"]\n",
    "\n",
    "    # Combine original history with new history\n",
    "    total_acc = acc + new_history.history[\"accuracy\"]\n",
    "    total_loss = loss + new_history.history[\"loss\"]\n",
    "\n",
    "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
    "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
    "\n",
    "    # Make plots\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(total_acc, label='Training Accuracy')\n",
    "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(total_loss, label='Training Loss')\n",
    "    plt.plot(total_val_loss, label='Validation Loss')\n",
    "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
    "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "  \n",
    "# Create function to unzip a zipfile into current working directory \n",
    "# (since we're going to be downloading and unzipping a few files)\n",
    "import zipfile\n",
    "\n",
    "def unzip_data(filename):\n",
    "  \"\"\"\n",
    "  Unzips filename into the current working directory.\n",
    "\n",
    "  Args:\n",
    "    filename (str): a filepath to a target zip folder to be unzipped.\n",
    "  \"\"\"\n",
    "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
    "  zip_ref.extractall()\n",
    "  zip_ref.close()\n",
    "\n",
    "# Walk through an image classification directory and find out how many files (images)\n",
    "# are in each subdirectory.\n",
    "import os\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"\n",
    "  Walks through dir_path returning its contents.\n",
    "\n",
    "  Args:\n",
    "    dir_path (str): target directory\n",
    "  \n",
    "  Returns:\n",
    "    A print out of:\n",
    "      number of subdiretories in dir_path\n",
    "      number of images (files) in each subdirectory\n",
    "      name of each subdirectory\n",
    "  \"\"\"\n",
    "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "    \n",
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "      y_true: true labels in the form of a 1D array\n",
    "      y_pred: predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d74bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = EffNetB0.history['accuracy']\n",
    "val_accuracy = EffNetB0.history['val_accuracy']\n",
    "\n",
    "loss = EffNetB0.history['loss']\n",
    "val_loss = EffNetB0.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.plot(epochs, accuracy, 'b', label='Training accuracy')\n",
    "ax1.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "ax1.set_title('Training and validation accuracy')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(epochs, loss, 'b', label='Training loss')\n",
    "ax2.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "ax2.set_title('Training and validation loss')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Training and validation metrics', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251b472",
   "metadata": {},
   "source": [
    "# Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chestScanPrediction(path, _model, actual_label):\n",
    "    classes_dir = [\"Adenocarcinoma\", \"Large cell carcinoma\", \"Normal\", \"Squamous cell carcinoma\"]\n",
    "    num_images = len(paths)\n",
    "    for i in range(num_images):\n",
    "        # Loading Image\n",
    "        img = image.load_img(paths[i], target_size=(350, 350))\n",
    "\n",
    "        # Normalizing Image\n",
    "        norm_img = image.img_to_array(img) / 255\n",
    "\n",
    "        # Converting Image to Numpy Array\n",
    "        input_arr_img = np.array([norm_img])\n",
    "\n",
    "        # Getting Predictions\n",
    "        pred = np.argmax(_model.predict(input_arr_img))\n",
    "\n",
    "        # Printing Model Prediction\n",
    "        print(\"Predicted Label:\", classes_dir[pred])\n",
    "        print(\"Actual Label:\", classes_dir[actual_label[i]])\n",
    "        \n",
    "        # Displaying the image\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Actual Label: \" + classes_dir[actual_label[i]] + \"\\nPredicted Label: \" + classes_dir[pred])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f65f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/test/large.cell.carcinoma/000124 (2).png\",\n",
    "    \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/test/adenocarcinoma/000158 (6).png\",\n",
    "    \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/test/normal/10 - Copy (3).png\",\n",
    "    \"C:/Users/ASUS/Desktop/Datasets for LUNG CANCER/Data/test/squamous.cell.carcinoma/000124.png\"\n",
    "]\n",
    "\n",
    "actual_labels = [1, 0, 2, 3]\n",
    "\n",
    "chestScanPrediction(paths, EffNetmodel, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c25178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1eb52a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
